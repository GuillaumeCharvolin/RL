_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1386.69, Loss: 0.4345
Epoch: 20, Avg Reward (last 10 runs): -1447.19, Loss: 0.6271
Epoch: 30, Avg Reward (last 10 runs): -1396.10, Loss: 1.0504
Epoch: 40, Avg Reward (last 10 runs): -1428.48, Loss: 3.6213
Epoch: 50, Avg Reward (last 10 runs): -1390.82, Loss: 1.6907
Epoch: 60, Avg Reward (last 10 runs): -1455.83, Loss: 4.3414
Epoch: 70, Avg Reward (last 10 runs): -1365.18, Loss: 9.1539
Epoch: 80, Avg Reward (last 10 runs): -1430.94, Loss: 1.2162
Epoch: 90, Avg Reward (last 10 runs): -1580.53, Loss: 3.0284
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1591.66, Loss: 0.7499
Epoch: 20, Avg Reward (last 10 runs): -1436.23, Loss: 0.2893
Epoch: 30, Avg Reward (last 10 runs): -1466.59, Loss: 1.2259
Epoch: 40, Avg Reward (last 10 runs): -1349.60, Loss: 5.7039
Epoch: 50, Avg Reward (last 10 runs): -1418.10, Loss: 3.3946
Epoch: 60, Avg Reward (last 10 runs): -1317.63, Loss: 4.1616
Epoch: 70, Avg Reward (last 10 runs): -1410.55, Loss: 5.1355
Epoch: 80, Avg Reward (last 10 runs): -1423.58, Loss: 2.6339
Epoch: 90, Avg Reward (last 10 runs): -1457.24, Loss: 3.4801
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1715.05, Loss: 0.5816
Epoch: 20, Avg Reward (last 10 runs): -1392.85, Loss: 0.4783
Epoch: 30, Avg Reward (last 10 runs): -1402.58, Loss: 0.3727
Epoch: 40, Avg Reward (last 10 runs): -1530.56, Loss: 0.3287
Epoch: 50, Avg Reward (last 10 runs): -1464.06, Loss: 0.7127
Epoch: 60, Avg Reward (last 10 runs): -1464.90, Loss: 0.1900
Epoch: 70, Avg Reward (last 10 runs): -1518.68, Loss: 0.5440
Epoch: 80, Avg Reward (last 10 runs): -1477.20, Loss: 1.0145
Epoch: 90, Avg Reward (last 10 runs): -1493.38, Loss: 0.7594
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1594.02, Loss: 0.4451
Epoch: 20, Avg Reward (last 10 runs): -1403.74, Loss: 0.4191
Epoch: 30, Avg Reward (last 10 runs): -1425.96, Loss: 0.2926
Epoch: 40, Avg Reward (last 10 runs): -1451.33, Loss: 0.3274
Epoch: 50, Avg Reward (last 10 runs): -1330.88, Loss: 0.1968
Epoch: 60, Avg Reward (last 10 runs): -1387.97, Loss: 0.6061
Epoch: 70, Avg Reward (last 10 runs): -1439.85, Loss: 0.5083
Epoch: 80, Avg Reward (last 10 runs): -1508.86, Loss: 0.8758
Epoch: 90, Avg Reward (last 10 runs): -1478.01, Loss: 0.6001
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1567.37, Loss: 0.5085
Epoch: 20, Avg Reward (last 10 runs): -1447.13, Loss: 0.5285
Epoch: 30, Avg Reward (last 10 runs): -1478.21, Loss: 0.7144
Epoch: 40, Avg Reward (last 10 runs): -1438.91, Loss: 2.3615
Epoch: 50, Avg Reward (last 10 runs): -1407.64, Loss: 2.5697
Epoch: 60, Avg Reward (last 10 runs): -1432.80, Loss: 4.7686
Epoch: 70, Avg Reward (last 10 runs): -1383.29, Loss: 12.2331
Epoch: 80, Avg Reward (last 10 runs): -1507.96, Loss: 2.4320
Epoch: 90, Avg Reward (last 10 runs): -1440.89, Loss: 5.2059
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1578.25, Loss: 0.7191
Epoch: 20, Avg Reward (last 10 runs): -1414.51, Loss: 0.3457
Epoch: 30, Avg Reward (last 10 runs): -1436.13, Loss: 0.8178
Epoch: 40, Avg Reward (last 10 runs): -1496.96, Loss: 3.3637
Epoch: 50, Avg Reward (last 10 runs): -1480.92, Loss: 1.5866
Epoch: 60, Avg Reward (last 10 runs): -1474.24, Loss: 1.9955
Epoch: 70, Avg Reward (last 10 runs): -1521.23, Loss: 2.5402
Epoch: 80, Avg Reward (last 10 runs): -1425.81, Loss: 2.6713
Epoch: 90, Avg Reward (last 10 runs): -1322.54, Loss: 3.4767
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1589.71, Loss: 0.6925
Epoch: 20, Avg Reward (last 10 runs): -1372.16, Loss: 0.1996
Epoch: 30, Avg Reward (last 10 runs): -1374.35, Loss: 0.2066
Epoch: 40, Avg Reward (last 10 runs): -1356.54, Loss: 0.2123
Epoch: 50, Avg Reward (last 10 runs): -1467.70, Loss: 0.1551
Epoch: 60, Avg Reward (last 10 runs): -1364.12, Loss: 0.7621
Epoch: 70, Avg Reward (last 10 runs): -1518.94, Loss: 0.2093
Epoch: 80, Avg Reward (last 10 runs): -1362.39, Loss: 0.5125
Epoch: 90, Avg Reward (last 10 runs): -1488.88, Loss: 1.1710
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1547.67, Loss: 0.5747
Epoch: 20, Avg Reward (last 10 runs): -1434.91, Loss: 0.3719
Epoch: 30, Avg Reward (last 10 runs): -1511.42, Loss: 0.3226
Epoch: 40, Avg Reward (last 10 runs): -1534.65, Loss: 0.2201
Epoch: 50, Avg Reward (last 10 runs): -1450.54, Loss: 0.3990
Epoch: 60, Avg Reward (last 10 runs): -1505.96, Loss: 0.4368
Epoch: 70, Avg Reward (last 10 runs): -1331.30, Loss: 0.3534
Epoch: 80, Avg Reward (last 10 runs): -1468.11, Loss: 1.2418
Epoch: 90, Avg Reward (last 10 runs): -1468.90, Loss: 0.7067
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1593.74, Loss: 0.5771
Epoch: 20, Avg Reward (last 10 runs): -1442.41, Loss: 0.6338
Epoch: 30, Avg Reward (last 10 runs): -1419.22, Loss: 0.6102
Epoch: 40, Avg Reward (last 10 runs): -1414.78, Loss: 2.3310
Epoch: 50, Avg Reward (last 10 runs): -1498.88, Loss: 2.7079
Epoch: 60, Avg Reward (last 10 runs): -1447.42, Loss: 5.0043
Epoch: 70, Avg Reward (last 10 runs): -1355.14, Loss: 11.5393
Epoch: 80, Avg Reward (last 10 runs): -1451.28, Loss: 1.8427
Epoch: 90, Avg Reward (last 10 runs): -1412.78, Loss: 2.3122
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1715.28, Loss: 0.6410
Epoch: 20, Avg Reward (last 10 runs): -1476.89, Loss: 0.6643
Epoch: 30, Avg Reward (last 10 runs): -1408.49, Loss: 0.5745
Epoch: 40, Avg Reward (last 10 runs): -1386.94, Loss: 2.5637
Epoch: 50, Avg Reward (last 10 runs): -1354.91, Loss: 5.5252
Epoch: 60, Avg Reward (last 10 runs): -1474.33, Loss: 1.7159
Epoch: 70, Avg Reward (last 10 runs): -1335.25, Loss: 3.1637
Epoch: 80, Avg Reward (last 10 runs): -1426.56, Loss: 7.1512
Epoch: 90, Avg Reward (last 10 runs): -1477.89, Loss: 2.2486
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1638.64, Loss: 0.7087
Epoch: 20, Avg Reward (last 10 runs): -1305.26, Loss: 0.2424
Epoch: 30, Avg Reward (last 10 runs): -1438.44, Loss: 0.2528
Epoch: 40, Avg Reward (last 10 runs): -1374.26, Loss: 0.4579
Epoch: 50, Avg Reward (last 10 runs): -1480.29, Loss: 0.2086
Epoch: 60, Avg Reward (last 10 runs): -1419.68, Loss: 1.1105
Epoch: 70, Avg Reward (last 10 runs): -1475.03, Loss: 1.3293
Epoch: 80, Avg Reward (last 10 runs): -1427.53, Loss: 0.3867
Epoch: 90, Avg Reward (last 10 runs): -1448.68, Loss: 3.2657
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1520.77, Loss: 0.5007
Epoch: 20, Avg Reward (last 10 runs): -1481.17, Loss: 0.2714
Epoch: 30, Avg Reward (last 10 runs): -1458.37, Loss: 0.1878
Epoch: 40, Avg Reward (last 10 runs): -1333.25, Loss: 0.2204
Epoch: 50, Avg Reward (last 10 runs): -1453.56, Loss: 0.2778
Epoch: 60, Avg Reward (last 10 runs): -1358.42, Loss: 0.4486
Epoch: 70, Avg Reward (last 10 runs): -1372.85, Loss: 0.9099
Epoch: 80, Avg Reward (last 10 runs): -1418.56, Loss: 0.1001
Epoch: 90, Avg Reward (last 10 runs): -1500.58, Loss: 0.0561
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1481.83, Loss: 0.5813
Epoch: 20, Avg Reward (last 10 runs): -1423.60, Loss: 0.3627
Epoch: 30, Avg Reward (last 10 runs): -1521.00, Loss: 1.2839
Epoch: 40, Avg Reward (last 10 runs): -1340.98, Loss: 1.5112
Epoch: 50, Avg Reward (last 10 runs): -1397.77, Loss: 7.3635
Epoch: 60, Avg Reward (last 10 runs): -1445.95, Loss: 5.9454
Epoch: 70, Avg Reward (last 10 runs): -1404.18, Loss: 4.1828
Epoch: 80, Avg Reward (last 10 runs): -1536.42, Loss: 3.0044
Epoch: 90, Avg Reward (last 10 runs): -1366.29, Loss: 4.0499
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1593.90, Loss: 1.0325
Epoch: 20, Avg Reward (last 10 runs): -1484.88, Loss: 1.1014
Epoch: 30, Avg Reward (last 10 runs): -1489.46, Loss: 1.0472
Epoch: 40, Avg Reward (last 10 runs): -1491.78, Loss: 2.7074
Epoch: 50, Avg Reward (last 10 runs): -1461.18, Loss: 1.0777
Epoch: 60, Avg Reward (last 10 runs): -1443.04, Loss: 4.9369
Epoch: 70, Avg Reward (last 10 runs): -1398.87, Loss: 6.1101
Epoch: 80, Avg Reward (last 10 runs): -1461.29, Loss: 5.7554
Epoch: 90, Avg Reward (last 10 runs): -1539.58, Loss: 3.7437
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1598.42, Loss: 0.5744
Epoch: 20, Avg Reward (last 10 runs): -1380.19, Loss: 0.5166
Epoch: 30, Avg Reward (last 10 runs): -1529.51, Loss: 0.3493
Epoch: 40, Avg Reward (last 10 runs): -1381.31, Loss: 0.4155
Epoch: 50, Avg Reward (last 10 runs): -1438.97, Loss: 0.1547
Epoch: 60, Avg Reward (last 10 runs): -1412.10, Loss: 0.9685
Epoch: 70, Avg Reward (last 10 runs): -1359.23, Loss: 0.5182
Epoch: 80, Avg Reward (last 10 runs): -1418.74, Loss: 0.7433
Epoch: 90, Avg Reward (last 10 runs): -1446.07, Loss: 0.6453
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1582.44, Loss: 0.3391
Epoch: 20, Avg Reward (last 10 runs): -1399.30, Loss: 0.2875
Epoch: 30, Avg Reward (last 10 runs): -1530.91, Loss: 0.2560
Epoch: 40, Avg Reward (last 10 runs): -1397.49, Loss: 0.2176
Epoch: 50, Avg Reward (last 10 runs): -1433.54, Loss: 0.2269
Epoch: 60, Avg Reward (last 10 runs): -1541.47, Loss: 0.7638
Epoch: 70, Avg Reward (last 10 runs): -1500.93, Loss: 0.2684
Epoch: 80, Avg Reward (last 10 runs): -1385.31, Loss: 0.3362
Epoch: 90, Avg Reward (last 10 runs): -1468.01, Loss: 0.7287
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1605.32, Loss: 0.8152
Epoch: 20, Avg Reward (last 10 runs): -1442.50, Loss: 0.8334
Epoch: 30, Avg Reward (last 10 runs): -1370.03, Loss: 0.4781
Epoch: 40, Avg Reward (last 10 runs): -1438.21, Loss: 1.2654
Epoch: 50, Avg Reward (last 10 runs): -1446.59, Loss: 2.3562
Epoch: 60, Avg Reward (last 10 runs): -1430.37, Loss: 3.2852
Epoch: 70, Avg Reward (last 10 runs): -1492.99, Loss: 3.1714
Epoch: 80, Avg Reward (last 10 runs): -1430.80, Loss: 2.0259
Epoch: 90, Avg Reward (last 10 runs): -1497.37, Loss: 2.9045
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1509.06, Loss: 0.6325
Epoch: 20, Avg Reward (last 10 runs): -1408.81, Loss: 0.4670
Epoch: 30, Avg Reward (last 10 runs): -1536.82, Loss: 0.5785
Epoch: 40, Avg Reward (last 10 runs): -1387.44, Loss: 0.8628
Epoch: 50, Avg Reward (last 10 runs): -1430.04, Loss: 2.3320
Epoch: 60, Avg Reward (last 10 runs): -1332.18, Loss: 6.4119
Epoch: 70, Avg Reward (last 10 runs): -1484.41, Loss: 3.2868
Epoch: 80, Avg Reward (last 10 runs): -1472.02, Loss: 2.0289
Epoch: 90, Avg Reward (last 10 runs): -1388.60, Loss: 2.5525
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1621.44, Loss: 0.6521
Epoch: 20, Avg Reward (last 10 runs): -1412.74, Loss: 0.3936
Epoch: 30, Avg Reward (last 10 runs): -1397.62, Loss: 0.1921
Epoch: 40, Avg Reward (last 10 runs): -1464.84, Loss: 0.4166
Epoch: 50, Avg Reward (last 10 runs): -1504.91, Loss: 0.4105
Epoch: 60, Avg Reward (last 10 runs): -1426.65, Loss: 0.8561
Epoch: 70, Avg Reward (last 10 runs): -1494.46, Loss: 0.4400
Epoch: 80, Avg Reward (last 10 runs): -1409.64, Loss: 1.5093
Epoch: 90, Avg Reward (last 10 runs): -1471.09, Loss: 1.0075
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1619.15, Loss: 0.3661
Epoch: 20, Avg Reward (last 10 runs): -1449.63, Loss: 0.1179
Epoch: 30, Avg Reward (last 10 runs): -1447.30, Loss: 0.1969
Epoch: 40, Avg Reward (last 10 runs): -1486.93, Loss: 0.1514
Epoch: 50, Avg Reward (last 10 runs): -1373.91, Loss: 0.2813
Epoch: 60, Avg Reward (last 10 runs): -1429.81, Loss: 0.2040
Epoch: 70, Avg Reward (last 10 runs): -1465.34, Loss: 0.6835
Epoch: 80, Avg Reward (last 10 runs): -1454.87, Loss: 0.4022
Epoch: 90, Avg Reward (last 10 runs): -1467.31, Loss: 0.7857
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1637.53, Loss: 0.5653
Epoch: 20, Avg Reward (last 10 runs): -1428.90, Loss: 0.6967
Epoch: 30, Avg Reward (last 10 runs): -1418.41, Loss: 1.3116
Epoch: 40, Avg Reward (last 10 runs): -1388.05, Loss: 1.3454
Epoch: 50, Avg Reward (last 10 runs): -1370.22, Loss: 4.1665
Epoch: 60, Avg Reward (last 10 runs): -1482.35, Loss: 4.8964
Epoch: 70, Avg Reward (last 10 runs): -1462.43, Loss: 3.4606
Epoch: 80, Avg Reward (last 10 runs): -1427.35, Loss: 6.9732
Epoch: 90, Avg Reward (last 10 runs): -1551.76, Loss: 4.2255
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1534.10, Loss: 0.4567
Epoch: 20, Avg Reward (last 10 runs): -1449.45, Loss: 0.3746
Epoch: 30, Avg Reward (last 10 runs): -1374.44, Loss: 0.7434
Epoch: 40, Avg Reward (last 10 runs): -1442.29, Loss: 2.6122
Epoch: 50, Avg Reward (last 10 runs): -1505.60, Loss: 4.0044
Epoch: 60, Avg Reward (last 10 runs): -1514.36, Loss: 2.0559
Epoch: 70, Avg Reward (last 10 runs): -1489.43, Loss: 2.3276
Epoch: 80, Avg Reward (last 10 runs): -1442.94, Loss: 4.1102
Epoch: 90, Avg Reward (last 10 runs): -1451.47, Loss: 2.4626
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1534.00, Loss: 0.4584
Epoch: 20, Avg Reward (last 10 runs): -1431.08, Loss: 0.3048
Epoch: 30, Avg Reward (last 10 runs): -1451.31, Loss: 0.4329
Epoch: 40, Avg Reward (last 10 runs): -1489.24, Loss: 0.4024
Epoch: 50, Avg Reward (last 10 runs): -1431.34, Loss: 0.4668
Epoch: 60, Avg Reward (last 10 runs): -1485.41, Loss: 0.5352
Epoch: 70, Avg Reward (last 10 runs): -1552.15, Loss: 0.3330
Epoch: 80, Avg Reward (last 10 runs): -1503.36, Loss: 1.0252
Epoch: 90, Avg Reward (last 10 runs): -1467.48, Loss: 1.0149
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1603.87, Loss: 0.4979
Epoch: 20, Avg Reward (last 10 runs): -1269.13, Loss: 0.2400
Epoch: 30, Avg Reward (last 10 runs): -1481.17, Loss: 0.1356
Epoch: 40, Avg Reward (last 10 runs): -1253.20, Loss: 0.1570
Epoch: 50, Avg Reward (last 10 runs): -1401.54, Loss: 0.2785
Epoch: 60, Avg Reward (last 10 runs): -1492.59, Loss: 0.1901
Epoch: 70, Avg Reward (last 10 runs): -1454.32, Loss: 0.6207
Epoch: 80, Avg Reward (last 10 runs): -1380.34, Loss: 0.3309
Epoch: 90, Avg Reward (last 10 runs): -1374.14, Loss: 2.2200
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1680.86, Loss: 0.3749
Epoch: 20, Avg Reward (last 10 runs): -1450.05, Loss: 0.5333
Epoch: 30, Avg Reward (last 10 runs): -1365.22, Loss: 1.4148
Epoch: 40, Avg Reward (last 10 runs): -1347.53, Loss: 2.1834
Epoch: 50, Avg Reward (last 10 runs): -1482.97, Loss: 2.3853
Epoch: 60, Avg Reward (last 10 runs): -1418.12, Loss: 5.3452
Epoch: 70, Avg Reward (last 10 runs): -1436.89, Loss: 4.5835
Epoch: 80, Avg Reward (last 10 runs): -1457.46, Loss: 7.0762
Epoch: 90, Avg Reward (last 10 runs): -1395.13, Loss: 1.5303
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1584.87, Loss: 0.6438
Epoch: 20, Avg Reward (last 10 runs): -1381.25, Loss: 0.4150
Epoch: 30, Avg Reward (last 10 runs): -1459.45, Loss: 0.7215
Epoch: 40, Avg Reward (last 10 runs): -1384.11, Loss: 2.6333
Epoch: 50, Avg Reward (last 10 runs): -1493.15, Loss: 3.7505
Epoch: 60, Avg Reward (last 10 runs): -1558.45, Loss: 6.4719
Epoch: 70, Avg Reward (last 10 runs): -1494.21, Loss: 3.8354
Epoch: 80, Avg Reward (last 10 runs): -1591.17, Loss: 1.4295
Epoch: 90, Avg Reward (last 10 runs): -1494.14, Loss: 2.3738
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1569.78, Loss: 0.5086
Epoch: 20, Avg Reward (last 10 runs): -1403.04, Loss: 0.2211
Epoch: 30, Avg Reward (last 10 runs): -1456.55, Loss: 0.1106
Epoch: 40, Avg Reward (last 10 runs): -1412.86, Loss: 0.1213
Epoch: 50, Avg Reward (last 10 runs): -1361.43, Loss: 0.1573
Epoch: 60, Avg Reward (last 10 runs): -1491.41, Loss: 0.4768
Epoch: 70, Avg Reward (last 10 runs): -1498.07, Loss: 0.7898
Epoch: 80, Avg Reward (last 10 runs): -1429.06, Loss: 0.5921
Epoch: 90, Avg Reward (last 10 runs): -1507.07, Loss: 1.5369
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1616.86, Loss: 0.2485
Epoch: 20, Avg Reward (last 10 runs): -1215.86, Loss: 0.1669
Epoch: 30, Avg Reward (last 10 runs): -1487.66, Loss: 0.1648
Epoch: 40, Avg Reward (last 10 runs): -1315.36, Loss: 0.1815
Epoch: 50, Avg Reward (last 10 runs): -1365.73, Loss: 0.6349
Epoch: 60, Avg Reward (last 10 runs): -1504.65, Loss: 0.7822
Epoch: 70, Avg Reward (last 10 runs): -1468.48, Loss: 0.5639
Epoch: 80, Avg Reward (last 10 runs): -1398.61, Loss: 0.5941
Epoch: 90, Avg Reward (last 10 runs): -1421.77, Loss: 0.4732
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1657.84, Loss: 1.1938
Epoch: 20, Avg Reward (last 10 runs): -1319.76, Loss: 0.7281
Epoch: 30, Avg Reward (last 10 runs): -1555.00, Loss: 1.0562
Epoch: 40, Avg Reward (last 10 runs): -1536.92, Loss: 1.1498
Epoch: 50, Avg Reward (last 10 runs): -1489.50, Loss: 2.2666
Epoch: 60, Avg Reward (last 10 runs): -1478.13, Loss: 4.1576
Epoch: 70, Avg Reward (last 10 runs): -1472.51, Loss: 3.6203
Epoch: 80, Avg Reward (last 10 runs): -1439.22, Loss: 8.6393
Epoch: 90, Avg Reward (last 10 runs): -1442.24, Loss: 3.5803
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1592.24, Loss: 0.6307
Epoch: 20, Avg Reward (last 10 runs): -1482.61, Loss: 0.6516
Epoch: 30, Avg Reward (last 10 runs): -1434.21, Loss: 0.9806
Epoch: 40, Avg Reward (last 10 runs): -1386.60, Loss: 1.6767
Epoch: 50, Avg Reward (last 10 runs): -1347.64, Loss: 1.3440
Epoch: 60, Avg Reward (last 10 runs): -1466.99, Loss: 4.2465
Epoch: 70, Avg Reward (last 10 runs): -1427.23, Loss: 6.2786
Epoch: 80, Avg Reward (last 10 runs): -1422.43, Loss: 12.4350
Epoch: 90, Avg Reward (last 10 runs): -1492.32, Loss: 3.2153
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1599.58, Loss: 0.1947
Epoch: 20, Avg Reward (last 10 runs): -1451.87, Loss: 0.1718
Epoch: 30, Avg Reward (last 10 runs): -1383.23, Loss: 0.1662
Epoch: 40, Avg Reward (last 10 runs): -1376.82, Loss: 0.2042
Epoch: 50, Avg Reward (last 10 runs): -1455.03, Loss: 0.4321
Epoch: 60, Avg Reward (last 10 runs): -1404.22, Loss: 0.6035
Epoch: 70, Avg Reward (last 10 runs): -1532.09, Loss: 0.5829
Epoch: 80, Avg Reward (last 10 runs): -1423.92, Loss: 0.5807
Epoch: 90, Avg Reward (last 10 runs): -1373.29, Loss: 2.0064
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 1000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1604.78, Loss: 0.5169
Epoch: 20, Avg Reward (last 10 runs): -1467.52, Loss: 0.1736
Epoch: 30, Avg Reward (last 10 runs): -1460.50, Loss: 0.1614
Epoch: 40, Avg Reward (last 10 runs): -1377.12, Loss: 0.2786
Epoch: 50, Avg Reward (last 10 runs): -1350.77, Loss: 0.2977
Epoch: 60, Avg Reward (last 10 runs): -1422.99, Loss: 0.6331
Epoch: 70, Avg Reward (last 10 runs): -1456.26, Loss: 0.6716
Epoch: 80, Avg Reward (last 10 runs): -1434.59, Loss: 1.2320
Epoch: 90, Avg Reward (last 10 runs): -1428.45, Loss: 1.4754
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1517.23, Loss: 0.7893
Epoch: 20, Avg Reward (last 10 runs): -1492.11, Loss: 0.4506
Epoch: 30, Avg Reward (last 10 runs): -1504.03, Loss: 0.4945
Epoch: 40, Avg Reward (last 10 runs): -1458.58, Loss: 1.2328
Epoch: 50, Avg Reward (last 10 runs): -1431.00, Loss: 2.8467
Epoch: 60, Avg Reward (last 10 runs): -1468.81, Loss: 3.9220
Epoch: 70, Avg Reward (last 10 runs): -1494.46, Loss: 2.6265
Epoch: 80, Avg Reward (last 10 runs): -1499.32, Loss: 4.8204
Epoch: 90, Avg Reward (last 10 runs): -1378.36, Loss: 4.6656
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1620.11, Loss: 0.6370
Epoch: 20, Avg Reward (last 10 runs): -1446.89, Loss: 0.3715
Epoch: 30, Avg Reward (last 10 runs): -1453.04, Loss: 0.6109
Epoch: 40, Avg Reward (last 10 runs): -1544.86, Loss: 1.9147
Epoch: 50, Avg Reward (last 10 runs): -1375.57, Loss: 3.1268
Epoch: 60, Avg Reward (last 10 runs): -1428.67, Loss: 2.7140
Epoch: 70, Avg Reward (last 10 runs): -1438.14, Loss: 6.6711
Epoch: 80, Avg Reward (last 10 runs): -1547.01, Loss: 4.0603
Epoch: 90, Avg Reward (last 10 runs): -1313.38, Loss: 3.2808
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1575.55, Loss: 1.0172
Epoch: 20, Avg Reward (last 10 runs): -1449.24, Loss: 0.2178
Epoch: 30, Avg Reward (last 10 runs): -1421.54, Loss: 0.3306
Epoch: 40, Avg Reward (last 10 runs): -1374.08, Loss: 0.3976
Epoch: 50, Avg Reward (last 10 runs): -1487.89, Loss: 0.4028
Epoch: 60, Avg Reward (last 10 runs): -1373.62, Loss: 0.4113
Epoch: 70, Avg Reward (last 10 runs): -1460.03, Loss: 0.8307
Epoch: 80, Avg Reward (last 10 runs): -1405.64, Loss: 0.8090
Epoch: 90, Avg Reward (last 10 runs): -1420.42, Loss: 1.5340
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1457.92, Loss: 0.6540
Epoch: 20, Avg Reward (last 10 runs): -1349.64, Loss: 0.3243
Epoch: 30, Avg Reward (last 10 runs): -1500.29, Loss: 0.1953
Epoch: 40, Avg Reward (last 10 runs): -1349.36, Loss: 0.5090
Epoch: 50, Avg Reward (last 10 runs): -1392.72, Loss: 0.3661
Epoch: 60, Avg Reward (last 10 runs): -1494.66, Loss: 0.4206
Epoch: 70, Avg Reward (last 10 runs): -1487.03, Loss: 0.5807
Epoch: 80, Avg Reward (last 10 runs): -1379.41, Loss: 0.8536
Epoch: 90, Avg Reward (last 10 runs): -1413.76, Loss: 1.4575
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1524.36, Loss: 0.4546
Epoch: 20, Avg Reward (last 10 runs): -1471.70, Loss: 0.5233
Epoch: 30, Avg Reward (last 10 runs): -1430.73, Loss: 0.9338
Epoch: 40, Avg Reward (last 10 runs): -1379.54, Loss: 2.5133
Epoch: 50, Avg Reward (last 10 runs): -1454.50, Loss: 3.0853
Epoch: 60, Avg Reward (last 10 runs): -1493.21, Loss: 4.8572
Epoch: 70, Avg Reward (last 10 runs): -1379.43, Loss: 6.3329
Epoch: 80, Avg Reward (last 10 runs): -1452.25, Loss: 4.6752
Epoch: 90, Avg Reward (last 10 runs): -1523.21, Loss: 4.1021
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1498.63, Loss: 0.6813
Epoch: 20, Avg Reward (last 10 runs): -1431.00, Loss: 0.8038
Epoch: 30, Avg Reward (last 10 runs): -1506.29, Loss: 1.1293
Epoch: 40, Avg Reward (last 10 runs): -1410.62, Loss: 1.7220
Epoch: 50, Avg Reward (last 10 runs): -1408.52, Loss: 3.9695
Epoch: 60, Avg Reward (last 10 runs): -1418.04, Loss: 6.1353
Epoch: 70, Avg Reward (last 10 runs): -1436.50, Loss: 7.6171
Epoch: 80, Avg Reward (last 10 runs): -1414.52, Loss: 5.5086
Epoch: 90, Avg Reward (last 10 runs): -1401.87, Loss: 5.9171
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1532.04, Loss: 0.6654
Epoch: 20, Avg Reward (last 10 runs): -1498.30, Loss: 0.3528
Epoch: 30, Avg Reward (last 10 runs): -1424.01, Loss: 0.3946
Epoch: 40, Avg Reward (last 10 runs): -1449.57, Loss: 0.4587
Epoch: 50, Avg Reward (last 10 runs): -1453.65, Loss: 0.4421
Epoch: 60, Avg Reward (last 10 runs): -1428.87, Loss: 0.4806
Epoch: 70, Avg Reward (last 10 runs): -1281.58, Loss: 0.6651
Epoch: 80, Avg Reward (last 10 runs): -1522.96, Loss: 1.0541
Epoch: 90, Avg Reward (last 10 runs): -1414.14, Loss: 1.2623
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1588.51, Loss: 0.3951
Epoch: 20, Avg Reward (last 10 runs): -1424.01, Loss: 0.2462
Epoch: 30, Avg Reward (last 10 runs): -1415.73, Loss: 0.1900
Epoch: 40, Avg Reward (last 10 runs): -1436.60, Loss: 0.2184
Epoch: 50, Avg Reward (last 10 runs): -1334.97, Loss: 0.5578
Epoch: 60, Avg Reward (last 10 runs): -1347.82, Loss: 0.3088
Epoch: 70, Avg Reward (last 10 runs): -1559.48, Loss: 0.6692
Epoch: 80, Avg Reward (last 10 runs): -1461.32, Loss: 0.9343
Epoch: 90, Avg Reward (last 10 runs): -1471.05, Loss: 1.2420
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1554.94, Loss: 0.7708
Epoch: 20, Avg Reward (last 10 runs): -1455.01, Loss: 0.6096
Epoch: 30, Avg Reward (last 10 runs): -1485.79, Loss: 1.0411
Epoch: 40, Avg Reward (last 10 runs): -1446.67, Loss: 1.1457
Epoch: 50, Avg Reward (last 10 runs): -1391.01, Loss: 2.8197
Epoch: 60, Avg Reward (last 10 runs): -1417.73, Loss: 4.0414
Epoch: 70, Avg Reward (last 10 runs): -1495.79, Loss: 4.9569
Epoch: 80, Avg Reward (last 10 runs): -1431.93, Loss: 8.3978
Epoch: 90, Avg Reward (last 10 runs): -1487.54, Loss: 4.3698
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1644.83, Loss: 0.3460
Epoch: 20, Avg Reward (last 10 runs): -1532.40, Loss: 0.4465
Epoch: 30, Avg Reward (last 10 runs): -1494.11, Loss: 0.7958
Epoch: 40, Avg Reward (last 10 runs): -1383.65, Loss: 1.4024
Epoch: 50, Avg Reward (last 10 runs): -1517.19, Loss: 1.4150
Epoch: 60, Avg Reward (last 10 runs): -1387.92, Loss: 4.3230
Epoch: 70, Avg Reward (last 10 runs): -1474.55, Loss: 3.5950
Epoch: 80, Avg Reward (last 10 runs): -1489.57, Loss: 3.4714
Epoch: 90, Avg Reward (last 10 runs): -1550.32, Loss: 0.8230
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1693.50, Loss: 0.3946
Epoch: 20, Avg Reward (last 10 runs): -1424.12, Loss: 0.1719
Epoch: 30, Avg Reward (last 10 runs): -1390.94, Loss: 0.1959
Epoch: 40, Avg Reward (last 10 runs): -1418.87, Loss: 0.3178
Epoch: 50, Avg Reward (last 10 runs): -1339.32, Loss: 0.3713
Epoch: 60, Avg Reward (last 10 runs): -1460.20, Loss: 0.3018
Epoch: 70, Avg Reward (last 10 runs): -1454.03, Loss: 0.6844
Epoch: 80, Avg Reward (last 10 runs): -1516.28, Loss: 1.1711
Epoch: 90, Avg Reward (last 10 runs): -1492.51, Loss: 1.8471
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1616.35, Loss: 0.4291
Epoch: 20, Avg Reward (last 10 runs): -1413.75, Loss: 0.1979
Epoch: 30, Avg Reward (last 10 runs): -1367.63, Loss: 0.2167
Epoch: 40, Avg Reward (last 10 runs): -1541.83, Loss: 0.3191
Epoch: 50, Avg Reward (last 10 runs): -1495.17, Loss: 0.5724
Epoch: 60, Avg Reward (last 10 runs): -1445.09, Loss: 0.2918
Epoch: 70, Avg Reward (last 10 runs): -1476.37, Loss: 0.6907
Epoch: 80, Avg Reward (last 10 runs): -1407.80, Loss: 0.6068
Epoch: 90, Avg Reward (last 10 runs): -1480.68, Loss: 1.0032
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1568.93, Loss: 0.9053
Epoch: 20, Avg Reward (last 10 runs): -1442.78, Loss: 0.6595
Epoch: 30, Avg Reward (last 10 runs): -1415.99, Loss: 1.1701
Epoch: 40, Avg Reward (last 10 runs): -1494.89, Loss: 2.7149
Epoch: 50, Avg Reward (last 10 runs): -1334.27, Loss: 4.6174
Epoch: 60, Avg Reward (last 10 runs): -1456.39, Loss: 3.6973
Epoch: 70, Avg Reward (last 10 runs): -1467.04, Loss: 1.9050
Epoch: 80, Avg Reward (last 10 runs): -1465.38, Loss: 4.3705
Epoch: 90, Avg Reward (last 10 runs): -1483.90, Loss: 5.0253
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1417.03, Loss: 0.4352
Epoch: 20, Avg Reward (last 10 runs): -1526.97, Loss: 0.9785
Epoch: 30, Avg Reward (last 10 runs): -1477.28, Loss: 1.0154
Epoch: 40, Avg Reward (last 10 runs): -1465.47, Loss: 1.2787
Epoch: 50, Avg Reward (last 10 runs): -1417.36, Loss: 4.0334
Epoch: 60, Avg Reward (last 10 runs): -1438.38, Loss: 2.7546
Epoch: 70, Avg Reward (last 10 runs): -1378.27, Loss: 5.3589
Epoch: 80, Avg Reward (last 10 runs): -1432.49, Loss: 10.1816
Epoch: 90, Avg Reward (last 10 runs): -1429.09, Loss: 6.1268
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1501.70, Loss: 0.4978
Epoch: 20, Avg Reward (last 10 runs): -1494.94, Loss: 0.2028
Epoch: 30, Avg Reward (last 10 runs): -1337.83, Loss: 0.1258
Epoch: 40, Avg Reward (last 10 runs): -1453.97, Loss: 0.2875
Epoch: 50, Avg Reward (last 10 runs): -1406.03, Loss: 0.2660
Epoch: 60, Avg Reward (last 10 runs): -1542.80, Loss: 0.4861
Epoch: 70, Avg Reward (last 10 runs): -1482.88, Loss: 0.5317
Epoch: 80, Avg Reward (last 10 runs): -1518.61, Loss: 1.5104
Epoch: 90, Avg Reward (last 10 runs): -1399.89, Loss: 1.2563
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 64, 'max_action_by_epoch': 200, 'replay_memory_size': 2000, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1575.81, Loss: 0.4530
Epoch: 20, Avg Reward (last 10 runs): -1547.85, Loss: 0.2353
Epoch: 30, Avg Reward (last 10 runs): -1421.77, Loss: 0.5297
Epoch: 40, Avg Reward (last 10 runs): -1363.91, Loss: 0.7521
Epoch: 50, Avg Reward (last 10 runs): -1514.11, Loss: 0.8737
Epoch: 60, Avg Reward (last 10 runs): -1484.18, Loss: 1.2986
Epoch: 70, Avg Reward (last 10 runs): -1461.45, Loss: 0.4964
Epoch: 80, Avg Reward (last 10 runs): -1339.61, Loss: 1.3145
Epoch: 90, Avg Reward (last 10 runs): -1468.79, Loss: 1.6557
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1677.41, Loss: 0.6632
Epoch: 20, Avg Reward (last 10 runs): -1388.56, Loss: 0.5910
Epoch: 30, Avg Reward (last 10 runs): -1441.77, Loss: 1.0484
Epoch: 40, Avg Reward (last 10 runs): -1429.01, Loss: 0.7100
Epoch: 50, Avg Reward (last 10 runs): -1395.22, Loss: 4.8768
Epoch: 60, Avg Reward (last 10 runs): -1496.86, Loss: 2.5028
Epoch: 70, Avg Reward (last 10 runs): -1464.79, Loss: 2.7994
Epoch: 80, Avg Reward (last 10 runs): -1498.67, Loss: 2.9601
Epoch: 90, Avg Reward (last 10 runs): -1353.67, Loss: 3.0396
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1550.13, Loss: 0.8952
Epoch: 20, Avg Reward (last 10 runs): -1416.95, Loss: 0.8091
Epoch: 30, Avg Reward (last 10 runs): -1365.02, Loss: 0.8495
Epoch: 40, Avg Reward (last 10 runs): -1294.01, Loss: 1.6617
Epoch: 50, Avg Reward (last 10 runs): -1349.63, Loss: 2.6336
Epoch: 60, Avg Reward (last 10 runs): -1460.98, Loss: 2.0953
Epoch: 70, Avg Reward (last 10 runs): -1401.03, Loss: 1.4756
Epoch: 80, Avg Reward (last 10 runs): -1390.68, Loss: 1.8175
Epoch: 90, Avg Reward (last 10 runs): -1393.11, Loss: 1.8046
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1544.28, Loss: 0.5449
Epoch: 20, Avg Reward (last 10 runs): -1463.67, Loss: 0.1301
Epoch: 30, Avg Reward (last 10 runs): -1403.82, Loss: 0.1609
Epoch: 40, Avg Reward (last 10 runs): -1458.56, Loss: 0.1349
Epoch: 50, Avg Reward (last 10 runs): -1512.00, Loss: 0.2363
Epoch: 60, Avg Reward (last 10 runs): -1546.31, Loss: 0.3344
Epoch: 70, Avg Reward (last 10 runs): -1420.73, Loss: 0.6408
Epoch: 80, Avg Reward (last 10 runs): -1420.41, Loss: 0.5320
Epoch: 90, Avg Reward (last 10 runs): -1355.26, Loss: 1.1856
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1585.40, Loss: 0.3958
Epoch: 20, Avg Reward (last 10 runs): -1436.36, Loss: 0.2115
Epoch: 30, Avg Reward (last 10 runs): -1428.49, Loss: 0.1826
Epoch: 40, Avg Reward (last 10 runs): -1293.16, Loss: 0.1784
Epoch: 50, Avg Reward (last 10 runs): -1370.60, Loss: 0.3639
Epoch: 60, Avg Reward (last 10 runs): -1467.33, Loss: 0.3531
Epoch: 70, Avg Reward (last 10 runs): -1498.42, Loss: 0.5771
Epoch: 80, Avg Reward (last 10 runs): -1460.64, Loss: 0.5415
Epoch: 90, Avg Reward (last 10 runs): -1401.96, Loss: 0.5486
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1570.53, Loss: 0.5738
Epoch: 20, Avg Reward (last 10 runs): -1445.36, Loss: 0.9392
Epoch: 30, Avg Reward (last 10 runs): -1494.66, Loss: 1.4084
Epoch: 40, Avg Reward (last 10 runs): -1489.73, Loss: 2.9991
Epoch: 50, Avg Reward (last 10 runs): -1513.30, Loss: 3.9338
Epoch: 60, Avg Reward (last 10 runs): -1448.48, Loss: 4.7612
Epoch: 70, Avg Reward (last 10 runs): -1400.34, Loss: 4.5246
Epoch: 80, Avg Reward (last 10 runs): -1515.84, Loss: 4.0048
Epoch: 90, Avg Reward (last 10 runs): -1462.62, Loss: 1.7393
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1732.58, Loss: 0.8932
Epoch: 20, Avg Reward (last 10 runs): -1393.30, Loss: 0.6038
Epoch: 30, Avg Reward (last 10 runs): -1459.44, Loss: 0.3788
Epoch: 40, Avg Reward (last 10 runs): -1484.39, Loss: 1.7938
Epoch: 50, Avg Reward (last 10 runs): -1448.55, Loss: 2.0012
Epoch: 60, Avg Reward (last 10 runs): -1481.53, Loss: 2.8612
Epoch: 70, Avg Reward (last 10 runs): -1365.62, Loss: 4.8076
Epoch: 80, Avg Reward (last 10 runs): -1447.70, Loss: 2.2370
Epoch: 90, Avg Reward (last 10 runs): -1356.35, Loss: 2.0382
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1525.99, Loss: 0.2670
Epoch: 20, Avg Reward (last 10 runs): -1400.70, Loss: 0.3781
Epoch: 30, Avg Reward (last 10 runs): -1387.34, Loss: 0.2173
Epoch: 40, Avg Reward (last 10 runs): -1424.69, Loss: 0.2613
Epoch: 50, Avg Reward (last 10 runs): -1432.61, Loss: 0.2137
Epoch: 60, Avg Reward (last 10 runs): -1469.15, Loss: 0.1507
Epoch: 70, Avg Reward (last 10 runs): -1391.10, Loss: 0.2186
Epoch: 80, Avg Reward (last 10 runs): -1473.03, Loss: 1.2893
Epoch: 90, Avg Reward (last 10 runs): -1406.45, Loss: 0.9873
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 200, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1468.37, Loss: 0.6382
Epoch: 20, Avg Reward (last 10 runs): -1368.26, Loss: 0.2841
Epoch: 30, Avg Reward (last 10 runs): -1433.67, Loss: 0.2038
Epoch: 40, Avg Reward (last 10 runs): -1538.05, Loss: 0.2057
Epoch: 50, Avg Reward (last 10 runs): -1476.03, Loss: 0.1865
Epoch: 60, Avg Reward (last 10 runs): -1509.15, Loss: 0.2742
Epoch: 70, Avg Reward (last 10 runs): -1433.00, Loss: 0.3786
Epoch: 80, Avg Reward (last 10 runs): -1498.79, Loss: 0.2173
Epoch: 90, Avg Reward (last 10 runs): -1365.98, Loss: 0.2828
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1587.43, Loss: 0.5458
Epoch: 20, Avg Reward (last 10 runs): -1436.54, Loss: 0.6385
Epoch: 30, Avg Reward (last 10 runs): -1315.60, Loss: 0.5759
Epoch: 40, Avg Reward (last 10 runs): -1250.30, Loss: 2.5597
Epoch: 50, Avg Reward (last 10 runs): -1371.52, Loss: 1.8743
Epoch: 60, Avg Reward (last 10 runs): -1452.46, Loss: 3.5403
Epoch: 70, Avg Reward (last 10 runs): -1317.98, Loss: 3.8414
Epoch: 80, Avg Reward (last 10 runs): -1456.87, Loss: 5.2571
Epoch: 90, Avg Reward (last 10 runs): -1438.79, Loss: 0.3393
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1631.18, Loss: 0.1198
Epoch: 20, Avg Reward (last 10 runs): -1455.58, Loss: 0.5688
Epoch: 30, Avg Reward (last 10 runs): -1438.88, Loss: 0.6029
Epoch: 40, Avg Reward (last 10 runs): -1274.95, Loss: 2.2912
Epoch: 50, Avg Reward (last 10 runs): -1519.37, Loss: 1.7508
Epoch: 60, Avg Reward (last 10 runs): -1502.53, Loss: 1.6221
Epoch: 70, Avg Reward (last 10 runs): -1501.79, Loss: 1.1381
Epoch: 80, Avg Reward (last 10 runs): -1440.49, Loss: 2.5956
Epoch: 90, Avg Reward (last 10 runs): -1506.56, Loss: 1.6078
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1593.35, Loss: 0.4168
Epoch: 20, Avg Reward (last 10 runs): -1385.49, Loss: 0.1705
Epoch: 30, Avg Reward (last 10 runs): -1466.58, Loss: 0.2105
Epoch: 40, Avg Reward (last 10 runs): -1440.97, Loss: 0.2149
Epoch: 50, Avg Reward (last 10 runs): -1417.86, Loss: 0.1369
Epoch: 60, Avg Reward (last 10 runs): -1439.59, Loss: 0.2624
Epoch: 70, Avg Reward (last 10 runs): -1417.24, Loss: 0.2839
Epoch: 80, Avg Reward (last 10 runs): -1438.14, Loss: 0.3500
Epoch: 90, Avg Reward (last 10 runs): -1477.47, Loss: 0.9406
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 0.99, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1546.05, Loss: 0.3162
Epoch: 20, Avg Reward (last 10 runs): -1510.51, Loss: 0.0774
Epoch: 30, Avg Reward (last 10 runs): -1428.54, Loss: 0.1405
Epoch: 40, Avg Reward (last 10 runs): -1499.86, Loss: 0.1737
Epoch: 50, Avg Reward (last 10 runs): -1536.97, Loss: 0.0362
Epoch: 60, Avg Reward (last 10 runs): -1447.63, Loss: 0.2999
Epoch: 70, Avg Reward (last 10 runs): -1499.31, Loss: 0.6181
Epoch: 80, Avg Reward (last 10 runs): -1410.37, Loss: 0.4997
Epoch: 90, Avg Reward (last 10 runs): -1348.39, Loss: 0.3499
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1594.71, Loss: 0.3343
Epoch: 20, Avg Reward (last 10 runs): -1466.43, Loss: 0.7117
Epoch: 30, Avg Reward (last 10 runs): -1429.27, Loss: 0.9613
Epoch: 40, Avg Reward (last 10 runs): -1330.94, Loss: 0.7563
Epoch: 50, Avg Reward (last 10 runs): -1490.12, Loss: 2.9396
Epoch: 60, Avg Reward (last 10 runs): -1524.96, Loss: 3.6305
Epoch: 70, Avg Reward (last 10 runs): -1310.85, Loss: 5.2709
Epoch: 80, Avg Reward (last 10 runs): -1428.67, Loss: 4.8741
Epoch: 90, Avg Reward (last 10 runs): -1439.78, Loss: 4.0584
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 5, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1576.76, Loss: 0.2815
Epoch: 20, Avg Reward (last 10 runs): -1418.67, Loss: 0.7687
Epoch: 30, Avg Reward (last 10 runs): -1390.08, Loss: 1.2117
Epoch: 40, Avg Reward (last 10 runs): -1400.95, Loss: 1.6643
Epoch: 50, Avg Reward (last 10 runs): -1326.31, Loss: 3.5913
Epoch: 60, Avg Reward (last 10 runs): -1367.28, Loss: 5.0509
Epoch: 70, Avg Reward (last 10 runs): -1388.44, Loss: 6.6906
Epoch: 80, Avg Reward (last 10 runs): -1482.04, Loss: 6.2346
Epoch: 90, Avg Reward (last 10 runs): -1397.79, Loss: 5.8406
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.995}
Epoch: 10, Avg Reward (last 10 runs): -1530.80, Loss: 0.4103
Epoch: 20, Avg Reward (last 10 runs): -1554.35, Loss: 0.2660
Epoch: 30, Avg Reward (last 10 runs): -1424.95, Loss: 0.1794
Epoch: 40, Avg Reward (last 10 runs): -1452.47, Loss: 0.3183
Epoch: 50, Avg Reward (last 10 runs): -1414.39, Loss: 0.1007
Epoch: 60, Avg Reward (last 10 runs): -1354.65, Loss: 0.3140
Epoch: 70, Avg Reward (last 10 runs): -1419.74, Loss: 1.0327
Epoch: 80, Avg Reward (last 10 runs): -1423.32, Loss: 0.9748
Epoch: 90, Avg Reward (last 10 runs): -1379.82, Loss: 1.5692
_________________
Testing with params: {'fixed_learning_rate': 0.0001, 'epsilon': 0.1, 'batch_size': 128, 'max_action_by_epoch': 200, 'replay_memory_size': 500, 'run_to_fill_replay': 300, 'max_epoch': 100, 'horizon': 1, 'update_q_step': 10, 'update_epsilon_decay': 0.99}
Epoch: 10, Avg Reward (last 10 runs): -1543.59, Loss: 0.5664
Epoch: 20, Avg Reward (last 10 runs): -1521.37, Loss: 0.1552
Epoch: 30, Avg Reward (last 10 runs): -1375.81, Loss: 0.1893
